{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport gc\nimport numpy as np\nimport os\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\n\npd.set_option('max_columns', 300)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-24T16:02:26.925803Z","iopub.execute_input":"2022-02-24T16:02:26.926524Z","iopub.status.idle":"2022-02-24T16:02:29.481719Z","shell.execute_reply.started":"2022-02-24T16:02:26.926429Z","shell.execute_reply":"2022-02-24T16:02:29.480857Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"output_labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim',\n                 'B-Counterclaim', 'I-Counterclaim', 'B-Rebuttal', 'I-Rebuttal',\n                 'B-Evidence', 'I-Evidence', 'B-Concluding', 'I-Concluding']\n\nreplace_labels = {'O': 'O', 'B-Lead': 'Lead', 'I-Lead': 'Lead', 'B-Position': 'Position', 'I-Position': 'Position', \n                  'B-Claim': 'Claim', 'I-Claim': 'Claim', 'B-Counterclaim': 'Counterclaim', 'I-Counterclaim': 'Counterclaim', \n                  'B-Rebuttal': 'Rebuttal', 'I-Rebuttal': 'Rebuttal', 'B-Evidence': 'Evidence', 'I-Evidence': 'Evidence', \n                  'B-Concluding': 'Concluding Statement', 'I-Concluding': 'Concluding Statement'}\n\nnum_labels = len(output_labels)\nkey2val = {k: v for v, k in enumerate(output_labels)}\nval2key = {v: k for v, k in enumerate(output_labels)}\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2022-02-24T16:02:29.483546Z","iopub.execute_input":"2022-02-24T16:02:29.484088Z","iopub.status.idle":"2022-02-24T16:02:29.548323Z","shell.execute_reply.started":"2022-02-24T16:02:29.484048Z","shell.execute_reply":"2022-02-24T16:02:29.547337Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def read_data(path):\n    df = pd.DataFrame()\n    id_list, text_list = [], []\n    for filename in os.listdir(path):\n        id_list.append(filename.split('.')[0])\n        with open(f'{path}/{filename}') as file:\n            text_list.append(file.read())\n    df['id'] = id_list\n    df['text'] = text_list\n    return df\n\n\ndef create_entities(df, df_labels):\n    df['entities'] = ''\n    #df['num_words'] = 0\n    #max_num_words = 0\n    for i in range(len(df)):\n        current_num_words = len(df.loc[i, 'text'].split())\n        #df.loc[i, 'num_words'] = current_num_words\n        #if current_num_words > max_num_words:\n        #    max_num_words = current_num_words\n        #    print(f'max_words: {max_num_words}')\n        file_id = df.loc[i, 'id']\n        pos_character_start_list = df_labels.loc[df_labels['id'] == file_id, 'discourse_start'].astype('int').tolist()\n        pos_character_end_list = df_labels.loc[df_labels['id'] == file_id, 'discourse_end'].astype('int').tolist()\n        labels_list = df_labels.loc[df_labels['id'] == file_id, 'discourse_type'].tolist()\n        entities = ['O' for _ in range(len(df.loc[i, 'text'].split()))]\n        for j in range(len(labels_list)):\n            pos_character_start, pos_character_end = pos_character_start_list[j], pos_character_end_list[j]\n            pos_word_start = len(df.loc[i, 'text'][:pos_character_start].split())\n            pos_word_end = len(df.loc[i, 'text'][:pos_character_end].split()) - 1\n            for k in range(pos_word_start, pos_word_end):\n                if k == pos_word_start:\n                    entities[k] = f'B-{labels_list[j].split()[0]}'\n                else:\n                    entities[k] = f'I-{labels_list[j].split()[0]}'\n        df.loc[i, 'entities'] = ' '.join(entities)\n\n    return df\n\n\ndef text_accuracy(preds, labels):\n    arr_length = 0\n    active_preds = dict()\n    active_labels = dict()\n    for i in range(len(preds)):\n        active_preds[i] = []\n        active_labels[i] = []\n        for j in range(len(preds[i])):\n            if labels[i][j] != -100:\n                active_preds[i].append(preds[i][j])\n                active_labels[i].append(labels[i][j])\n                arr_length += 1\n\n    metric_preds = np.zeros(arr_length)\n    metric_labels = np.zeros(arr_length)\n    current_pos = 0\n    for i in range(len(active_preds)):\n        for j in range(len(active_preds[i])):\n            metric_preds[current_pos] = active_preds[i][j]\n            metric_labels[current_pos] = active_labels[i][j]\n            current_pos += 1\n    \n    return accuracy_score(metric_labels, metric_preds)\n\n\ndef preds2submission(preds, file_id_list):\n    id_list, label_list, predictionstring_list = [], [], []\n    for i in range(len(preds)):\n        last_label = 'O'\n        words_count = 0\n        predictionstring = ''\n        for j in range(len(preds[i])):\n            current_label = replace_labels[val2key[preds[i][j]]]\n            if current_label != last_label:\n                if last_label != 'O':\n                    id_list.append(file_id_list[i])\n                    label_list.append(last_label)\n                    predictionstring_list.append(predictionstring)\n                    \n                    if current_label != 'O':\n                        predictionstring = str(words_count)\n                \"\"\"else:\n                    predictionstring_list.append(predictionstring)\n                    id_list.append(file_id_list[i])\n                    predictionstring = ''\"\"\"\n            elif current_label == last_label and current_label != 'O':\n                predictionstring += f' {words_count}'\n            \n            if j == len(preds[i]) - 1 and current_label != 'O':\n                id_list.append(file_id_list[i])\n                label_list.append(current_label)\n                predictionstring_list.append(predictionstring)\n                \n            last_label = current_label\n            words_count += 1\n\n    print(f'id: {len(id_list)}')\n    print(f'class: {len(label_list)}')\n    print(f'pred: {len(predictionstring_list)}')\n    df = pd.DataFrame({'id': id_list, 'class': label_list, 'predictionstring': predictionstring_list})\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-02-24T16:02:29.553073Z","iopub.execute_input":"2022-02-24T16:02:29.553335Z","iopub.status.idle":"2022-02-24T16:02:29.580614Z","shell.execute_reply.started":"2022-02-24T16:02:29.553304Z","shell.execute_reply":"2022-02-24T16:02:29.579800Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, data, tokenizer, max_length, is_label=False):\n        self.text = data['text']\n        self.entities = data['entities'] if is_label else None\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.is_label = is_label\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, index):\n        #print(f'text1: {self.text}')\n        #print(f'\\n\\n\\ntext2: {self.text[index]}')\n        encoding = self.tokenizer(self.text[index].split(), is_split_into_words=True, truncation=True,\n                                  padding='max_length', max_length=self.max_length)\n\n        if self.is_label:\n            entities_list = self.entities[index].split()\n            word_ids = encoding.word_ids()\n            labels = []\n            for word_id in word_ids:\n                if word_id is None:\n                    labels.append(-100)\n                else:\n                    labels.append(key2val[entities_list[word_id]])\n            encoding['labels'] = labels\n\n        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n\n        return item\n\n\nclass TextModel:\n    def __init__(self, model_name, max_length, num_folds=5):\n        self.models = []\n        self.model_name = model_name\n        self.num_folds = num_folds\n        self.tokenizer = None\n        self.max_length = max_length\n\n    def fit(self, data, batch_size=4, lr=2.5e-5, epochs=1):\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name, add_prefix_space=True)\n\n        full_preds = np.zeros((len(data), self.max_length))\n        full_labels = np.zeros((len(data), self.max_length))\n\n        kfold = KFold(n_splits=self.num_folds, shuffle=True, random_state=0)\n        for trn_ind, val_ind in kfold.split(data):\n            data_train = data.loc[trn_ind]\n            data_train.index = range(len(data_train))\n            data_val = data.loc[val_ind]\n            data_val.index = range(len(data_val))\n\n            dataset_train = TextDataset(data_train, self.tokenizer, max_length=self.max_length, is_label=True)\n            loader_train = DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=False, pin_memory=True)\n\n            dataset_val = TextDataset(data_val, self.tokenizer, max_length=self.max_length, is_label=True)\n            loader_val = DataLoader(dataset=dataset_val, batch_size=batch_size, shuffle=False, pin_memory=True)\n\n            model = AutoModelForTokenClassification.from_pretrained(self.model_name, num_labels=num_labels).to(device)\n            optimizer = optim.Adam(params=model.parameters(), lr=lr)\n\n            #print(f\"model: {model}\")\n\n            for epoch in range(epochs):\n                print(f'epoch: {epoch+1}')\n                model.train()\n                for batch in tqdm(loader_train):\n                    #print(batch['input_ids'].shape)\n                    #print(batch['attention_mask'].shape)\n                    #print(batch['labels'].shape)\n                    input_ids = batch['input_ids'].to(device)\n                    attention_mask = batch['attention_mask'].to(device)\n                    labels = batch['labels'].to(device)\n\n                    loss, _ = model(input_ids=input_ids, attention_mask=attention_mask,\n                                    labels=labels, return_dict=False)\n\n                    optimizer.zero_grad()\n                    loss.backward()\n                    optimizer.step()\n\n                with torch.no_grad():\n                    model.eval()\n                    current_pos = 0\n                    temp_preds = np.zeros((len(data_val), self.max_length))\n                    temp_labels = np.zeros((len(data_val), self.max_length))\n                    for batch in tqdm(loader_val):\n                        input_ids = batch['input_ids'].to(device)\n                        attention_mask = batch['attention_mask'].to(device)\n                        labels = batch['labels'].to(device)\n                        current_batch_size = len(batch['input_ids'])\n\n                        _, logit_preds = model(input_ids=input_ids, attention_mask=attention_mask,\n                                               labels=labels, return_dict=False)\n                        #print(f'logit_fit: {logit_preds}')\n                        flattened_preds = torch.argmax(logit_preds.view(-1, model.num_labels), dim=1)\n                        #active_labels_mask = labels.view(-1) != -100\n                        #preds = torch.masked_select(flattened_preds, active_labels_mask)\n                        #print(f'preds1: {flattened_preds.view(batch_size, -1).shape}')\n                        #print(f'preds2: {preds.shape}')\n                        #print(f'preds3: {preds[current_pos:current_pos + batch_size].shape}')\n                        temp_preds[current_pos:current_pos+current_batch_size] = flattened_preds.view(current_batch_size, -1).cpu().numpy()\n                        temp_labels[current_pos:current_pos+current_batch_size] = labels.cpu().numpy()\n                        current_pos += current_batch_size\n                    full_preds[val_ind] = temp_preds\n                    full_labels[val_ind] = temp_labels\n                    \n                    print(f'temp_preds: {temp_preds}')\n            \n        self.models.append(model)\n        torch.cuda.empty_cache()\n        gc.collect()\n\n        print(f'full_preds: {full_preds} shape: {full_preds.shape}')\n\n        return full_preds, full_labels\n    \n    def predict(self, data, batch_size=4, is_label=False):\n        dataset = TextDataset(data, self.tokenizer, max_length=self.max_length, is_label=is_label)\n        loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n        \n        preds = np.zeros((len(data), self.max_length, num_labels))\n        labels = np.zeros((len(data), self.max_length))\n        \n        with torch.no_grad():\n            for model in self.models:\n                model.eval()\n                current_pos = 0\n                for batch in tqdm(loader):\n                    input_ids = batch['input_ids'].to(device)\n                    attention_mask = batch['attention_mask'].to(device)\n                    labels_temp = None\n                    current_batch_size = len(batch['input_ids'])\n                    if is_label:\n                        labels_temp = batch['labels'].to(device)\n                        _, logit_preds = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels_temp, return_dict=False)\n                        labels[current_pos:current_pos+batch_size] = labels_temp.cpu().numpy()\n                    else:\n                        logit_preds = model(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)[0]\n                    #flattened_preds = logit_preds.view(-1, model.num_labels)\n                    #active_labels_mask = labels.view(-1) != -100\n                    print(f'logit: {logit_preds}')\n                    preds[current_pos:current_pos+current_batch_size] += logit_preds.cpu().numpy()\n                    #preds[current_pos:current_pos+batch_size] = flattened_preds.view(batch_size, -1).cpu().numpy()\n                    current_pos += current_batch_size\n        preds = preds / self.num_folds\n        return np.argmax(preds, axis=2), labels","metadata":{"execution":{"iopub.status.busy":"2022-02-24T16:02:29.582895Z","iopub.execute_input":"2022-02-24T16:02:29.583169Z","iopub.status.idle":"2022-02-24T16:02:29.618344Z","shell.execute_reply.started":"2022-02-24T16:02:29.583135Z","shell.execute_reply":"2022-02-24T16:02:29.617563Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_labels = pd.read_csv('../input/feedback-prize-2021/train.csv')\ndf_train = read_data('../input/feedback-prize-2021/train')\n\ndf_train, df_val = train_test_split(df_train, test_size=0.2, shuffle=True, random_state=0)\n\ndf_train.index = range(len(df_train))\ndf_train = create_entities(df_train, df_labels)\n\ndf_val.index = range(len(df_val))\ndf_val = create_entities(df_val, df_labels)\n\ndf_test = read_data('../input/feedback-prize-2021/test')\n\nmodel = TextModel(model_name='../input/huggingfacebigbirdrobertabase', max_length=1024)\nval_preds, val_labels = model.fit(df_train)\npreds, labels = model.predict(df_val, is_label=True)\ntest_preds, _ = model.predict(df_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T16:02:29.619694Z","iopub.execute_input":"2022-02-24T16:02:29.620131Z","iopub.status.idle":"2022-02-24T17:00:15.423567Z","shell.execute_reply.started":"2022-02-24T16:02:29.620092Z","shell.execute_reply":"2022-02-24T17:00:15.422256Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"text_accuracy(val_preds, val_labels)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T17:00:15.424773Z","iopub.status.idle":"2022-02-24T17:00:15.425504Z","shell.execute_reply.started":"2022-02-24T17:00:15.425205Z","shell.execute_reply":"2022-02-24T17:00:15.425236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = preds2submission(preds, df_val['id'])\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2022-02-24T17:00:15.427131Z","iopub.status.idle":"2022-02-24T17:00:15.428034Z","shell.execute_reply.started":"2022-02-24T17:00:15.427737Z","shell.execute_reply":"2022-02-24T17:00:15.427767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-24T17:00:15.429283Z","iopub.status.idle":"2022-02-24T17:00:15.430173Z","shell.execute_reply.started":"2022-02-24T17:00:15.429896Z","shell.execute_reply":"2022-02-24T17:00:15.429930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"arr_length = 0\nactive_preds = dict()\nactive_labels = dict()\nfor i in range(len(preds)):\n    active_preds[i] = []\n    active_labels[i] = []\n    for j in range(len(preds[i])):\n        if labels[i][j] != -100:\n            active_preds[i].append(preds[i][j])\n            active_labels[i].append(labels[i][j])\n            arr_length += 1\n\nmetric_preds = np.zeros(arr_length)\nmetric_labels = np.zeros(arr_length)\ncurrent_pos = 0\nfor i in range(len(active_preds)):\n    for j in range(len(active_preds[i])):\n        metric_preds[current_pos] = active_preds[i][j]\n        metric_labels[current_pos] = active_labels[i][j]\n        current_pos += 1\naccuracy_score(metric_labels, metric_preds)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-02-24T17:00:15.431526Z","iopub.status.idle":"2022-02-24T17:00:15.432381Z","shell.execute_reply.started":"2022-02-24T17:00:15.432101Z","shell.execute_reply":"2022-02-24T17:00:15.432133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
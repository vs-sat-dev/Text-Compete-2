{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport gc\nimport numpy as np\nimport os\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom tqdm import tqdm\n\npd.set_option('max_columns', 300)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-28T12:30:40.411108Z","iopub.execute_input":"2022-02-28T12:30:40.411659Z","iopub.status.idle":"2022-02-28T12:30:43.156061Z","shell.execute_reply.started":"2022-02-28T12:30:40.411543Z","shell.execute_reply":"2022-02-28T12:30:43.155174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim',\n                 'B-Counterclaim', 'I-Counterclaim', 'B-Rebuttal', 'I-Rebuttal',\n                 'B-Evidence', 'I-Evidence', 'B-Concluding', 'I-Concluding']\n\nreplace_labels = {'O': 'O', 'B-Lead': 'Lead', 'I-Lead': 'Lead', 'B-Position': 'Position', 'I-Position': 'Position', \n                  'B-Claim': 'Claim', 'I-Claim': 'Claim', 'B-Counterclaim': 'Counterclaim', 'I-Counterclaim': 'Counterclaim', \n                  'B-Rebuttal': 'Rebuttal', 'I-Rebuttal': 'Rebuttal', 'B-Evidence': 'Evidence', 'I-Evidence': 'Evidence', \n                  'B-Concluding': 'Concluding Statement', 'I-Concluding': 'Concluding Statement'}\n\nnum_labels = len(output_labels)\nkey2val = {k: v for v, k in enumerate(output_labels)}\nval2key = {v: k for v, k in enumerate(output_labels)}\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2022-02-28T12:30:43.160816Z","iopub.execute_input":"2022-02-28T12:30:43.161068Z","iopub.status.idle":"2022-02-28T12:30:43.220565Z","shell.execute_reply.started":"2022-02-28T12:30:43.161035Z","shell.execute_reply":"2022-02-28T12:30:43.219624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_data(path):\n    df = pd.DataFrame()\n    id_list, text_list = [], []\n    for filename in os.listdir(path):\n        id_list.append(filename.split('.')[0])\n        with open(f'{path}/{filename}') as file:\n            text_list.append(file.read())\n    df['id'] = id_list\n    df['text'] = text_list\n    return df\n\n\ndef create_entities(df, df_labels):\n    df['entities'] = ''\n    for i in range(len(df)):\n        current_num_words = len(df.loc[i, 'text'].split())\n        file_id = df.loc[i, 'id']\n        pos_character_start_list = df_labels.loc[df_labels['id'] == file_id, 'discourse_start'].astype('int').tolist()\n        pos_character_end_list = df_labels.loc[df_labels['id'] == file_id, 'discourse_end'].astype('int').tolist()\n        labels_list = df_labels.loc[df_labels['id'] == file_id, 'discourse_type'].tolist()\n        entities = ['O' for _ in range(len(df.loc[i, 'text'].split()))]\n        \n        for j in range(len(labels_list)):\n            pos_character_start, pos_character_end = pos_character_start_list[j], pos_character_end_list[j]\n            pos_word_start = len(df.loc[i, 'text'][:pos_character_start].split())\n            pos_word_end = len(df.loc[i, 'text'][:pos_character_end].split()) - 1\n            for k in range(pos_word_start, pos_word_end):\n                if k == pos_word_start:\n                    entities[k] = f'B-{labels_list[j].split()[0]}'\n                else:\n                    entities[k] = f'I-{labels_list[j].split()[0]}'\n        df.loc[i, 'entities'] = ' '.join(entities)\n\n    return df\n\n\ndef text_f1(labels, preds, word_ids):\n    arr_length = 0\n    active_preds = dict()\n    active_labels = dict()\n    \n    last_word_id = -100\n    \n    for i in range(len(preds)):\n        active_preds[i] = []\n        active_labels[i] = []\n        for j in range(len(preds[i])):\n            #print(f'label: {labels[i][j]} pred: {preds[i][j]}')\n            current_word_id = word_ids[i][j]\n            if labels[i][j] != -100 and current_word_id != last_word_id:\n                active_preds[i].append(preds[i][j])\n                active_labels[i].append(labels[i][j])\n                arr_length += 1\n            last_word_id = current_word_id\n\n    metric_preds = np.zeros(arr_length)\n    metric_labels = np.zeros(arr_length)\n    current_pos = 0\n    for i in range(len(active_preds)):\n        for j in range(len(active_preds[i])):\n            metric_preds[current_pos] = active_preds[i][j]\n            metric_labels[current_pos] = active_labels[i][j]\n            current_pos += 1\n    \n    return f1_score(metric_labels, metric_preds, average='weighted')\n\n\ndef preds2submission(preds, file_id_list, word_ids):\n    id_list, label_list, predictionstring_list = [], [], []\n    for i in range(len(preds)):\n        last_label = 'O'\n        words_count = 0\n        predictionstring = ''\n        last_word_id = -100\n        is_not_finished = True\n        for j in range(len(preds[i])):\n            current_label = replace_labels[val2key[preds[i][j]]]\n            current_word_id = word_ids[i][j]\n            #print(f'cur_word_id: {current_word_id} last_word_id: {last_word_id} cur_label: {current_label} last_label: {last_label} i: {i} j: {j}')\n            if current_word_id == -100 or current_word_id == last_word_id:\n                #print('Continue')\n                \n                if current_word_id == -100 and j > 0 and last_label != 'O' and current_label != 'O' and is_not_finished:\n                    id_list.append(file_id_list[i])\n                    label_list.append(current_label)\n                    predictionstring_list.append(predictionstring)\n                    is_not_finished = False\n                \n                continue\n            if current_label != last_label:\n                if last_label != 'O':\n                    id_list.append(file_id_list[i])\n                    label_list.append(last_label)\n                    predictionstring_list.append(predictionstring)\n                    \n                    if current_label != 'O':\n                        predictionstring = str(words_count)\n                else:\n                    predictionstring = str(words_count)\n            elif current_label == last_label and current_label != 'O':\n                predictionstring += f' {words_count}'\n            \n            \"\"\"if j == len(preds[i]) - 1 and current_label != 'O':\n                id_list.append(file_id_list[i])\n                label_list.append(current_label)\n                predictionstring_list.append(predictionstring)\"\"\"\n                \n            last_word_id = current_word_id\n            last_label = current_label\n            words_count += 1\n\n    print(f'id: {len(id_list)}')\n    print(f'class: {len(label_list)}')\n    print(f'pred: {len(predictionstring_list)}')\n    df = pd.DataFrame({'id': id_list, 'class': label_list, 'predictionstring': predictionstring_list})\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-02-28T12:30:43.222506Z","iopub.execute_input":"2022-02-28T12:30:43.222805Z","iopub.status.idle":"2022-02-28T12:30:43.267277Z","shell.execute_reply.started":"2022-02-28T12:30:43.222766Z","shell.execute_reply":"2022-02-28T12:30:43.266458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, data, tokenizer, max_length, is_label=False):\n        self.text = data['text']\n        self.entities = data['entities'] if is_label else None\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.is_label = is_label\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, index):\n        encoding = self.tokenizer(self.text[index].split(), is_split_into_words=True, truncation=True,\n                                  padding='max_length', max_length=self.max_length)\n        word_ids = encoding.word_ids()\n        return_word_ids = []\n\n        if self.is_label:\n            entities_list = self.entities[index].split()\n        labels = []\n        for word_id in word_ids:\n            if word_id is None:\n                return_word_ids.append(-100)\n                if self.is_label:\n                    labels.append(-100)\n            else:\n                return_word_ids.append(word_id)\n                if self.is_label:\n                    labels.append(key2val[entities_list[word_id]])\n        \n        if self.is_label:\n            encoding['labels'] = labels\n\n        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n\n        return item, np.array(return_word_ids)\n\n\nclass TextModel:\n    def __init__(self, model_name, max_length):\n        self.model_name = model_name\n        self.num_folds = 5\n        self.tokenizer = None\n        self.max_length = max_length\n\n    def fit(self, data, batch_size=4, lr=2.5e-5, epochs=1, num_folds=5):\n        \n        self.num_folds = num_folds\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name, add_prefix_space=True)\n\n        full_preds = np.zeros((len(data), self.max_length))\n        full_labels = np.zeros((len(data), self.max_length))\n\n        kfold = KFold(n_splits=self.num_folds, shuffle=True, random_state=0)\n        for fold, (trn_ind, val_ind) in enumerate(kfold.split(data)):\n            data_train = data.loc[trn_ind]\n            data_train.index = range(len(data_train))\n            data_val = data.loc[val_ind]\n            data_val.index = range(len(data_val))\n\n            dataset_train = TextDataset(data_train, self.tokenizer, max_length=self.max_length, is_label=True)\n            loader_train = DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=False, pin_memory=True)\n\n            dataset_val = TextDataset(data_val, self.tokenizer, max_length=self.max_length, is_label=True)\n            loader_val = DataLoader(dataset=dataset_val, batch_size=batch_size, shuffle=False, pin_memory=True)\n\n            model = AutoModelForTokenClassification.from_pretrained(self.model_name, num_labels=num_labels).to(device)\n            \n            optimizer = optim.Adam(params=model.parameters(), lr=lr)\n\n            for epoch in range(epochs):\n                print(f'epoch: {epoch+1}')\n                model.train()\n                for batch, _ in tqdm(loader_train):\n                    input_ids = batch['input_ids'].to(device)\n                    attention_mask = batch['attention_mask'].to(device)\n                    labels = batch['labels'].to(device)\n\n                    loss, _ = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels, return_dict=False)\n\n                    optimizer.zero_grad()\n                    loss.backward()\n                    optimizer.step()\n\n                with torch.no_grad():\n                    model.eval()\n                    current_pos = 0\n                    temp_preds = np.zeros((len(data_val), self.max_length))\n                    temp_labels = np.zeros((len(data_val), self.max_length))\n                    temp_words = np.zeros((len(data), self.max_length))\n                    for batch, word_ids in tqdm(loader_val):\n                        input_ids = batch['input_ids'].to(device)\n                        attention_mask = batch['attention_mask'].to(device)\n                        labels = batch['labels'].to(device)\n                        current_batch_size = len(batch['input_ids'])\n\n                        _, logit_preds = model(input_ids=input_ids, attention_mask=attention_mask,\n                                               labels=labels, return_dict=False)\n                        flattened_preds = torch.argmax(logit_preds.view(-1, model.num_labels), dim=1)\n                        temp_preds[current_pos:current_pos+current_batch_size] = flattened_preds.view(current_batch_size, -1).cpu().numpy()\n                        temp_labels[current_pos:current_pos+current_batch_size] = labels.cpu().numpy()\n                        temp_words[current_pos:current_pos+current_batch_size] = word_ids\n                        current_pos += current_batch_size\n                    full_preds[val_ind] = temp_preds\n                    full_labels[val_ind] = temp_labels\n                    \n                    print(f'f1_score: {text_f1(temp_labels, temp_preds, temp_words)}')\n            \n            torch.cuda.empty_cache()\n            gc.collect()\n            torch.save(model.state_dict(), f'./{self.model_name.split(\"/\")[-1]}{fold+1}.pt')\n\n        print(f'full_preds: {full_preds} shape: {full_preds.shape}')\n\n        return full_preds, full_labels\n    \n    def predict(self, data, batch_size=4, is_label=False):\n        dataset = TextDataset(data, self.tokenizer, max_length=self.max_length, is_label=is_label)\n        loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n        \n        preds = np.zeros((len(data), self.max_length, num_labels))\n        labels = np.zeros((len(data), self.max_length))\n        words = np.zeros((len(data), self.max_length))\n        \n        with torch.no_grad():\n            for fold in range(self.num_folds):\n                model = AutoModelForTokenClassification.from_pretrained(self.model_name, num_labels=num_labels).to(device)\n                model.load_state_dict(torch.load(f'./{self.model_name.split(\"/\")[-1]}{fold+1}.pt'))\n                model.eval()\n                current_pos = 0\n                for batch, word_ids in tqdm(loader):\n                    input_ids = batch['input_ids'].to(device)\n                    attention_mask = batch['attention_mask'].to(device)\n                    labels_temp = None\n                    current_batch_size = len(batch['input_ids'])\n                    if is_label:\n                        labels_temp = batch['labels'].to(device)\n                        _, logit_preds = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels_temp, return_dict=False)\n                        labels[current_pos:current_pos+batch_size] = labels_temp.cpu().numpy()\n                    else:\n                        logit_preds = model(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)[0]\n                    #print(f'\\nwids: {word_ids} \\nwids_len: {len(word_ids)} \\nwords: {words} \\nwords_len: {len(words)}')\n                    #print(f'w_ids_shape: {word_ids.shape} words_shape: {words.shape} words_batch_shape: {words[current_pos:current_pos+current_batch_size].shape}')\n                    preds[current_pos:current_pos+current_batch_size] += logit_preds.cpu().numpy()\n                    words[current_pos:current_pos+current_batch_size] = word_ids\n                    current_pos += current_batch_size\n        preds = preds / self.num_folds\n        return np.argmax(preds, axis=2), labels, words","metadata":{"execution":{"iopub.status.busy":"2022-02-28T12:30:43.271495Z","iopub.execute_input":"2022-02-28T12:30:43.271906Z","iopub.status.idle":"2022-02-28T12:30:43.309291Z","shell.execute_reply.started":"2022-02-28T12:30:43.271848Z","shell.execute_reply":"2022-02-28T12:30:43.308497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_labels = pd.read_csv('../input/feedback-prize-2021/train.csv')\ndf_train = read_data('../input/feedback-prize-2021/train')\n\n#df_train, df_val = train_test_split(df_train, test_size=0.2, shuffle=True, random_state=0)\n\ndf_train.index = range(len(df_train))\ndf_train = create_entities(df_train, df_labels)\n\n#df_val.index = range(len(df_val))\n#df_val = create_entities(df_val, df_labels)\n\ndf_test = read_data('../input/feedback-prize-2021/test')\n\nmodel = TextModel(model_name='../input/huggingfacebigbirdrobertabase', max_length=1024)\n#model = TextModel(model_name='../input/py-bigbird-v26', max_length=1024)\nval_preds, val_labels = model.fit(df_train)\n#preds, labels, word_ids = model.predict(df_val, is_label=True)\ntest_preds, _, test_word_ids = model.predict(df_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T12:30:43.310731Z","iopub.execute_input":"2022-02-28T12:30:43.311206Z","iopub.status.idle":"2022-02-28T12:32:43.999948Z","shell.execute_reply.started":"2022-02-28T12:30:43.311166Z","shell.execute_reply":"2022-02-28T12:32:43.999252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#text_f1(labels, preds, word_ids)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T12:32:44.001482Z","iopub.execute_input":"2022-02-28T12:32:44.002336Z","iopub.status.idle":"2022-02-28T12:32:44.027468Z","shell.execute_reply.started":"2022-02-28T12:32:44.002297Z","shell.execute_reply":"2022-02-28T12:32:44.026689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = preds2submission(test_preds, df_test['id'], test_word_ids)\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2022-02-28T12:32:44.029092Z","iopub.execute_input":"2022-02-28T12:32:44.029359Z","iopub.status.idle":"2022-02-28T12:32:44.056483Z","shell.execute_reply.started":"2022-02-28T12:32:44.029321Z","shell.execute_reply":"2022-02-28T12:32:44.055807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T12:32:44.057698Z","iopub.execute_input":"2022-02-28T12:32:44.058715Z","iopub.status.idle":"2022-02-28T12:32:44.065979Z","shell.execute_reply.started":"2022-02-28T12:32:44.058676Z","shell.execute_reply":"2022-02-28T12:32:44.065217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}